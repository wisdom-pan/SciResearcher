"""
MinerUæ‰¹é‡å¤„ç†ä¼˜åŒ–æ¨¡å—
MVPå®žçŽ°ï¼šç®€åŒ–ç‰ˆæ‰¹é‡PDFå¤„ç†åŠŸèƒ½
"""
import os
import json
import time
from pathlib import Path
from typing import List, Dict, Optional
import zipfile
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed

# ====================== æ‰¹é‡å¤„ç†é…ç½® ======================
MAX_WORKERS = 2  # å¹¶å‘å¤„ç†æ•°é‡
MAX_RETRY = 60  # æœ€å¤§é‡è¯•æ¬¡æ•°
RETRY_INTERVAL = 10  # é‡è¯•é—´éš”(ç§’)
SAVE_DIR = "/data/parse_results"  # ç»“æžœä¿å­˜ç›®å½•

# ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
os.makedirs(SAVE_DIR, exist_ok=True)

# ====================== æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ======================

def apply_upload_url(token: str, filename: str) -> Optional[tuple]:
    """ç”³è¯·ä¸´æ—¶ä¸Šä¼ URL"""
    url = "https://mineru.net/api/v4/file-urls/batch"
    headers = {"Authorization": f"Bearer {token}"}
    data = {
        "files": [{"name": filename}],
        "model_version": "vlm"
    }

    try:
        response = requests.post(url, headers=headers, json=data, timeout=30)
        result = response.json()

        if result["code"] == 0:
            return result["data"]["batch_id"], result["data"]["file_urls"][0]
        else:
            print(f"âŒ ç”³è¯·URLå¤±è´¥: {result['msg']}")
            return None
    except Exception as e:
        print(f"âŒ ç”³è¯·URLå¼‚å¸¸: {str(e)}")
        return None

def upload_pdf(upload_url: str, pdf_path: str) -> bool:
    """é€šè¿‡PUTæ–¹å¼ä¸Šä¼ PDF"""
    try:
        with open(pdf_path, "rb") as f:
            response = requests.put(upload_url, data=f, timeout=60)
        return response.status_code in (200, 201)
    except Exception as e:
        print(f"âŒ ä¸Šä¼ å¼‚å¸¸: {str(e)}")
        return False

def poll_result(token: str, batch_id: str, filename: str) -> Optional[str]:
    """è½®è¯¢è§£æžç»“æžœ"""
    query_url = f"https://mineru.net/api/v4/extract-results/batch/{batch_id}"

    for retry in range(MAX_RETRY):
        try:
            # æŸ¥è¯¢çŠ¶æ€
            response = requests.get(query_url, headers={"Authorization": f"Bearer {token}"}, timeout=30)
            response.raise_for_status()  # æ•èŽ·HTTPé”™è¯¯ï¼ˆ4xx/5xxï¼‰
            result = response.json()

            # æ ¡éªŒæŽ¥å£è¿”å›žç 
            if result["code"] != 0:
                print(f"âŒ ç¬¬{retry+1}æ¬¡æŸ¥è¯¢å¤±è´¥ï¼š{result['msg']}")
                time.sleep(RETRY_INTERVAL)
                continue

            # æå–æ ¸å¿ƒå­—æ®µï¼ˆä¸¥æ ¼åŒ¹é…æŽ¥å£è¿”å›žç»“æž„ï¼‰
            extract_result = result["data"]["extract_result"]
            if not extract_result:
                print(f"âŒ ç¬¬{retry+1}æ¬¡æŸ¥è¯¢ï¼šextract_resultä¸ºç©º")
                time.sleep(RETRY_INTERVAL)
                continue

            task_info = extract_result[0]
            task_state = task_info["state"]
            task_err_msg = task_info.get("err_msg", "")
            full_zip_url = task_info.get("full_zip_url", "")

            # æ‰“å°å…³é”®æ—¥å¿—ï¼ˆä¾¿äºŽæŽ’æŸ¥ï¼‰
            zip_url_preview = full_zip_url[:60] if full_zip_url else "ç©º"
            print(f"ðŸ“Œ ç¬¬{retry+1}/{MAX_RETRY}æ¬¡æŸ¥è¯¢ | çŠ¶æ€ï¼š{task_state} | ZIPé“¾æŽ¥ï¼š{zip_url_preview} | é”™è¯¯ï¼š{task_err_msg}")

            # çŠ¶æ€åˆ¤æ–­é€»è¾‘
            if task_state == "done":
                if full_zip_url:
                    # ä¸‹è½½åŽ‹ç¼©åŒ…
                    zip_save_path = os.path.join(SAVE_DIR, f"{batch_id}.zip")
                    print(f"\nâœ… è§£æžå®Œæˆï¼å¼€å§‹ä¸‹è½½åŽ‹ç¼©åŒ…ï¼š{full_zip_url[:60]}...")
                    zip_response = requests.get(full_zip_url, timeout=60)
                    zip_response.raise_for_status()
                    with open(zip_save_path, "wb") as f:
                        f.write(zip_response.content)
                    print(f"âœ… åŽ‹ç¼©åŒ…ä¸‹è½½å®Œæˆï¼š{zip_save_path}")

                    # è§£åŽ‹å¹¶æå–MDæ–‡ä»¶
                    pdf_name = os.path.splitext(filename)[0]
                    md_filename = f"{pdf_name}.md"
                    with ZipFile(zip_save_path, "r") as zf:
                        zf.extractall(SAVE_DIR)

                    # éªŒè¯MDæ–‡ä»¶
                    md_file_path = os.path.join(SAVE_DIR, md_filename)
                    if os.path.exists(md_file_path):
                        print(f"âœ… MDæ–‡ä»¶æå–æˆåŠŸï¼è·¯å¾„ï¼š{md_file_path}")
                        # é¢„è§ˆMDæ–‡ä»¶å‰200å­—ç¬¦
                        with open(md_file_path, "r", encoding="utf-8") as f:
                            preview = f.read(200)
                            print(f"\nðŸ“ MDæ–‡ä»¶å†…å®¹é¢„è§ˆï¼š\n{preview}...")
                        return md_file_path
                    else:
                        print(f"âŒ è§£åŽ‹æˆåŠŸä½†æœªæ‰¾åˆ°MDæ–‡ä»¶ï¼š{md_filename}")
                        # åˆ—å‡ºè§£åŽ‹åŽçš„æ–‡ä»¶ï¼Œä¾¿äºŽæŽ’æŸ¥
                        extracted_files = os.listdir(SAVE_DIR)
                        print(f"ðŸ“‚ è§£åŽ‹åŽçš„æ–‡ä»¶åˆ—è¡¨ï¼š{extracted_files}")
                        return None
                else:
                    print(f"âš ï¸ çŠ¶æ€ä¸ºdoneï¼Œä½†full_zip_urlä¸ºç©ºï¼Œç»ˆæ­¢è½®è¯¢")
                    return None
            elif task_state == "failed":
                print(f"âŒ è§£æžä»»åŠ¡å¤±è´¥ï¼š{task_err_msg}")
                return None
            else:
                # ä»»åŠ¡ä»åœ¨å¤„ç†ä¸­ï¼ˆpending/running/convertingï¼‰
                time.sleep(RETRY_INTERVAL)

        except Exception as e:
            print(f"âŒ ç¬¬{retry+1}æ¬¡æŸ¥è¯¢å¼‚å¸¸ï¼š{str(e)}")
            time.sleep(RETRY_INTERVAL)

    # è½®è¯¢è¶…æ—¶
    print(f"\nâŒ è½®è¯¢è¶…æ—¶ï¼ˆå·²é‡è¯•{MAX_RETRY}æ¬¡ï¼‰ï¼Œè¯·æ‰‹åŠ¨æŸ¥è¯¢ï¼š")
    print(f"æ‰‹åŠ¨æŸ¥è¯¢URLï¼š{query_url}")
    return None

def process_single_pdf(pdf_path: str, token: str) -> Dict:
    """
    å¤„ç†å•ä¸ªPDFæ–‡ä»¶
    :param pdf_path: PDFæ–‡ä»¶è·¯å¾„
    :param token: MinerU API Token
    :return: å¤„ç†ç»“æžœå­—å…¸ {æ–‡ä»¶è·¯å¾„, æˆåŠŸçŠ¶æ€, ç»“æžœè·¯å¾„/é”™è¯¯ä¿¡æ¯}
    """
    result = {
        "pdf_path": pdf_path,
        "success": False,
        "result": None
    }

    if not os.path.exists(pdf_path):
        result["result"] = f"æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}"
        return result

    filename = os.path.basename(pdf_path)
    print(f"\n{'='*60}")
    print(f"å¤„ç†æ–‡ä»¶: {filename}")
    print(f"{'='*60}")

    try:
        # 1. ç”³è¯·ä¸´æ—¶ä¸Šä¼ URL
        print(f"ðŸ“¤ ç”³è¯·ä¸Šä¼ URL...")
        batch_info = apply_upload_url(token, filename)
        if not batch_info:
            result["result"] = "ç”³è¯·ä¸Šä¼ URLå¤±è´¥"
            return result

        batch_id, upload_url = batch_info

        # 2. ä¸Šä¼ æ–‡ä»¶
        print(f"ðŸ“¤ ä¸Šä¼ æ–‡ä»¶...")
        if not upload_pdf(upload_url, pdf_path):
            result["result"] = "æ–‡ä»¶ä¸Šä¼ å¤±è´¥"
            return result

        # 3. è½®è¯¢è§£æžç»“æžœ
        print(f"â³ ç­‰å¾…è§£æžå®Œæˆ...")
        md_path = poll_result(token, batch_id, filename)

        if md_path:
            result["success"] = True
            result["result"] = md_path
            print(f"âœ… è§£æžå®Œæˆ: {md_path}")
        else:
            result["result"] = "è§£æžå¤±è´¥"

    except Exception as e:
        result["result"] = f"å¤„ç†å¼‚å¸¸: {str(e)}"
        print(f"âŒ {result['result']}")

    return result

def process_batch(pdf_paths: List[str], token: str) -> Dict:
    """
    æ‰¹é‡å¤„ç†PDFæ–‡ä»¶
    :param pdf_paths: PDFæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    :param token: MinerU API Token
    :return: å¤„ç†ç»“æžœå­—å…¸ {æ–‡ä»¶è·¯å¾„: ç»“æžœ}
    """
    results = {}
    success_count = 0
    fail_count = 0

    print(f"ðŸ“¦ å¼€å§‹æ‰¹é‡å¤„ç† {len(pdf_paths)} ä¸ªPDFæ–‡ä»¶")

    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_pdf = {executor.submit(process_single_pdf, pdf_path, token): pdf_path
                        for pdf_path in pdf_paths}

        for future in as_completed(future_to_pdf):
            pdf_path = future_to_pdf[future]
            try:
                result = future.result()
                results[pdf_path] = result["result"]

                if result["success"]:
                    success_count += 1
                    print(f"âœ… æˆåŠŸ: {os.path.basename(pdf_path)}")
                else:
                    fail_count += 1
                    print(f"âŒ å¤±è´¥: {os.path.basename(pdf_path)} - {result['result']}")

            except Exception as e:
                results[pdf_path] = f"å¤„ç†å¼‚å¸¸: {str(e)}"
                fail_count += 1
                print(f"âŒ å¼‚å¸¸: {os.path.basename(pdf_path)} - {str(e)}")

    # æ‰“å°æ±‡æ€»
    print(f"\n{'='*60}")
    print("æ‰¹é‡å¤„ç†æ±‡æ€»:")
    print(f"{'='*60}")
    print(f"æ€»æ•°: {len(pdf_paths)} | æˆåŠŸ: {success_count} | å¤±è´¥: {fail_count}")

    return results

# ====================== ä¾¿æ·å‡½æ•° ======================

def get_pdf_files(directory: str) -> List[str]:
    """èŽ·å–ç›®å½•ä¸­çš„æ‰€æœ‰PDFæ–‡ä»¶"""
    if not os.path.exists(directory):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {directory}")
        return []

    pdf_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.pdf')]
    return sorted(pdf_files)

def process_directory(directory: str, token: str) -> Dict:
    """å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰PDFæ–‡ä»¶"""
    pdf_files = get_pdf_files(directory)
    if not pdf_files:
        print(f"âŒ ç›®å½•ä¸­æ²¡æœ‰PDFæ–‡ä»¶: {directory}")
        return {}

    return process_batch(pdf_files, token)

# ====================== ä¸»å‡½æ•° ======================
if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šå¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰PDF
    import sys
    if len(sys.argv) > 1:
        directory = sys.argv[1]
        token = os.getenv("MINERU_API_TOKEN", "your_token_here")
        process_directory(directory, token)
    else:
        print("ç”¨æ³•: python mineru_batch.py <PDFç›®å½•è·¯å¾„>")