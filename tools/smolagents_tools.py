"""
åŸºäº smolagents çš„å·¥å…·é›†
å®Œå…¨ä½¿ç”¨APIå®ç°ï¼Œæ— æœ¬åœ°ä¾èµ–
"""
from smolagents import tool
from pathlib import Path
import json
import requests
import zipfile
import io
import time
from typing import List, Dict
from openai import OpenAI
import os

# ============================================================================
# MinerU API å°è£…å‡½æ•°
# ============================================================================

def create_task(file_url: str, file_path: str = None) -> str:
    """
    åˆ›å»ºMinerUè§£æä»»åŠ¡
    æ”¯æŒURLå’Œæœ¬åœ°æ–‡ä»¶ä¸Šä¼ 
    """
    token = os.getenv("MINERU_API_TOKEN")
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {token}"
    }

    # å¦‚æœæä¾›äº†æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œåˆ™ä½¿ç”¨ä¸´æ—¶URLä¸Šä¼ æ–¹å¼
    if file_path and os.path.exists(file_path):
        pdf_filename = os.path.basename(file_path)
        print(f"ğŸ“¤ æ­£åœ¨ç”³è¯·ä¸´æ—¶ä¸Šä¼ URL: {pdf_filename}")

        # 1. ç”³è¯·æ‰¹é‡ä¸Šä¼ URL
        apply_url = "https://mineru.net/api/v4/file-urls/batch"
        request_data = {
            "files": [{"name": pdf_filename}],
            "model_version": "vlm"
        }

        try:
            apply_res = requests.post(apply_url, headers=headers, json=request_data)
            apply_res.raise_for_status()
            apply_data = apply_res.json()

            if apply_data["code"] != 0:
                raise RuntimeError(f"ç”³è¯·ä¸Šä¼ URLå¤±è´¥: {apply_data['msg']}")

            batch_id = apply_data["data"]["batch_id"]
            upload_url = apply_data["data"]["file_urls"][0]
            print(f"âœ… ç”³è¯·ä¸´æ—¶ä¸Šä¼ URLæˆåŠŸï¼Œbatch_id: {batch_id}")
        except Exception as e:
            raise RuntimeError(f"ç”³è¯·ä¸Šä¼ URLå¼‚å¸¸: {str(e)}")

        # 2. PUTæ–¹å¼ä¸Šä¼ æ–‡ä»¶åˆ°OSSï¼ˆæ ¸å¿ƒï¼šç»•è¿‡ç½‘å…³payloadé™åˆ¶ï¼‰
        try:
            print(f"ğŸ“¤ æ­£åœ¨é€šè¿‡PUTæ–¹å¼ä¸Šä¼ æ–‡ä»¶...")
            with open(file_path, "rb") as f:
                upload_res = requests.put(upload_url, data=f)

            if upload_res.status_code not in (200, 201):
                raise RuntimeError(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼šçŠ¶æ€ç {upload_res.status_code}")

            print(f"âœ… PDFæ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼ˆPUTæ–¹å¼ï¼‰")
        except Exception as e:
            raise RuntimeError(f"æ–‡ä»¶ä¸Šä¼ å¼‚å¸¸: {str(e)}")

        # 3. è¿”å›batch_idä½œä¸ºtask_id
        return batch_id

    # å¦‚æœä½¿ç”¨çš„æ˜¯URLï¼Œåˆ™ä½¿ç”¨åŸæ¥çš„URLè§£ææ–¹å¼
    else:
        url = 'https://mineru.net/api/v4/extract/task'
        header = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {token}'
        }
        data = {
            'url': file_url,
            'is_ocr': True,
            'enable_formula': True,
            'enable_table': True,
            'language': "ch",
            'model_version': "v2"
        }
        res = requests.post(url, headers=header, json=data, timeout=30)

        res.raise_for_status()
        res_data = res.json()

        if res_data["code"] != 0:
            raise RuntimeError(f"ä»»åŠ¡æäº¤å¤±è´¥: {res_data['msg']}")

        task_id_data = res_data["data"]["task_id"]
        return task_id_data


def query_by_id(task_id: str, max_retries: int = 60, retry_interval: int = 10) -> str:
    """
    ä¼˜åŒ–åçš„è½®è¯¢æŸ¥è¯¢è§£æç»“æœï¼ˆå…ˆåˆ¤æ–­çŠ¶æ€ï¼Œå†å¤„ç†full_zip_urlï¼‰
    æ”¯æŒæ‰¹é‡ç»“æœæŸ¥è¯¢å’Œè¯¦ç»†çŠ¶æ€åé¦ˆ
    """
    # ä½¿ç”¨æ‰¹é‡ç»“æœæŸ¥è¯¢ç«¯ç‚¹
    url = f'https://mineru.net/api/v4/extract-results/batch/{task_id}'
    token = os.getenv("MINERU_API_TOKEN")
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {token}'
    }

    retries = 0
    while retries < max_retries:
        try:
            res = requests.get(url, headers=headers, timeout=30)
            res.raise_for_status()  # æ•è·HTTPè¯·æ±‚é”™è¯¯
            data = res.json()

            if data["code"] != 0:
                print(f"âŒ æŸ¥è¯¢è§£æçŠ¶æ€å¤±è´¥ï¼š{data['msg']}")
                break

            # æ ¸å¿ƒï¼šå…ˆè·å–ä»»åŠ¡çŠ¶æ€ï¼Œå†åˆ¤æ–­æ˜¯å¦è¯»å–full_zip_url
            extract_result = data["data"]["extract_result"]
            if not extract_result:
                print(f"âŒ ç¬¬{retries+1}æ¬¡æŸ¥è¯¢ï¼šextract_resultä¸ºç©º")
                time.sleep(retry_interval)
                retries += 1
                continue

            task_info = extract_result[0]
            task_state = task_info["state"]
            task_err_msg = task_info.get("err_msg", "")

            # çŠ¶æ€åˆ†ç±»å¤„ç†
            if task_state == "done":
                # ä»»åŠ¡å®Œæˆï¼Œæ£€æŸ¥full_zip_urlæ˜¯å¦æœ‰æ•ˆ
                full_zip_url = task_info.get("full_zip_url", "")
                if full_zip_url:
                    print(f"âœ… ä»»åŠ¡å®Œæˆï¼è·å–åˆ°ç»“æœURL")
                    return full_zip_url
                else:
                    print(f"âš ï¸ ä»»åŠ¡çŠ¶æ€ä¸ºdoneï¼Œä½†full_zip_urlä¸ºç©ºï¼Œé‡è¯•ç¬¬{retries+1}æ¬¡...")

            elif task_state == "failed":
                print(f"âŒ è§£æä»»åŠ¡å¤±è´¥ï¼š{task_err_msg}")
                raise Exception(f"è§£æä»»åŠ¡å¤±è´¥ï¼š{task_err_msg}")

            else:
                # ä»»åŠ¡å¤„ç†ä¸­ï¼ˆpending/running/convertingï¼‰
                print(f"â³ è§£æä¸­ï¼ˆçŠ¶æ€ï¼š{task_state}ï¼‰ï¼Œfull_zip_urlæš‚æœªç”Ÿæˆï¼Œç­‰å¾…{retry_interval}ç§’... å·²é‡è¯•{retries+1}æ¬¡")

            # æœªå®Œæˆåˆ™ç­‰å¾…é‡è¯•
            time.sleep(retry_interval)
            retries += 1

        except requests.exceptions.RequestException as e:
            print(f"âŒ æŸ¥è¯¢è§£æç»“æœå¼‚å¸¸ï¼š{str(e)}ï¼Œé‡è¯•ç¬¬{retries+1}æ¬¡...")
            time.sleep(retry_interval)
            retries += 1

    # æœ€ç»ˆç»“æœåˆ¤æ–­
    raise Exception(f"è§£æè¶…æ—¶ï¼ˆè¶…è¿‡{max_retries*retry_interval/60}åˆ†é’Ÿï¼‰ï¼Œè¯·æ£€æŸ¥ä»»åŠ¡çŠ¶æ€æˆ–è”ç³»MinerUå®˜æ–¹")


def download_and_extract_zip(zip_url: str) -> Dict[str, any]:
    """
    ä¸‹è½½å¹¶æå–ZIPæ–‡ä»¶å†…å®¹
    ä¼˜å…ˆä½¿ç”¨full.mdä½œä¸ºæœ€ç»ˆè§£ææ–‡ä»¶
    """
    print(f"ğŸ“¥ Downloading: {zip_url[:60]}...")
    res = requests.get(zip_url, timeout=300)
    res.raise_for_status()

    result = {"markdown": "", "content_list": [], "tables": [], "images": []}

    with zipfile.ZipFile(io.BytesIO(res.content)) as zf:
        # æ ¸å¿ƒï¼šä¼˜å…ˆæŸ¥æ‰¾full.mdï¼ˆMinerUé»˜è®¤çš„å®Œæ•´è§£æç»“æœæ–‡ä»¶ï¼‰
        md_file_found = False
        for md_filename in ["full.md", "output.md", "parsed.md", "document.md"]:
            try:
                markdown_content = zf.read(md_filename).decode("utf-8")
                result["markdown"] = markdown_content
                print(f"âœ… æˆåŠŸè¯»å–è§£ææ–‡ä»¶: {md_filename}")
                md_file_found = True
                break
            except KeyError:
                continue

        if not md_file_found:
            print("âš ï¸ æœªæ‰¾åˆ°æ ‡å‡†MDæ–‡ä»¶ï¼Œåˆ—å‡ºå‹ç¼©åŒ…å†…å®¹ä»¥ä¾¿æ’æŸ¥:")
            for name in zf.namelist():
                print(f"  - {name}")

        # Content List
        try:
            result["content_list"] = json.loads(zf.read("content_list.json"))
        except KeyError:
            pass

        # Tables
        try:
            tables_html = zf.read("tables.html").decode("utf-8")
            result["tables_html"] = tables_html
        except KeyError:
            pass

        # Images
        try:
            result["images"] = [
                {"path_in_zip": name}
                for name in zf.namelist()
                if name.startswith("images/") and (name.endswith(".jpg") or name.endswith(".png"))
            ]
        except Exception:
            pass

    # éªŒè¯markdownå†…å®¹æ˜¯å¦å®Œæ•´
    if result["markdown"]:
        markdown_preview = result["markdown"][:300]
        print(f"\nğŸ“ è§£æå†…å®¹é¢„è§ˆ:\n{markdown_preview}...")
        print(f"âœ… å®Œæ•´è§£æç»“æœæå–å®Œæˆ (æ€»é•¿åº¦: {len(result['markdown'])} å­—ç¬¦)")
    else:
        print("âš ï¸ è­¦å‘Š: æœªèƒ½æå–åˆ°Markdownå†…å®¹")

    return result


# ============================================================================
# Tool 1: PDFè§£æå·¥å…· (ä½¿ç”¨ MinerU API)
# ============================================================================

@tool
def parse_pdf(pdf_url: str, local_file_path: str = None) -> str:
    """
    Parse a PDF file using MinerU API.

    Args:
        pdf_url: URL to the PDF file (used if local_file_path not provided)
        local_file_path: Path to local PDF file (preferred if provided)

    Returns:
        JSON string containing extracted content
    """
    try:
        api_token = os.getenv("MINERU_API_TOKEN")
        if not api_token:
            return json.dumps({"error": "MINERU_API_TOKEN not configured"})

        # å¦‚æœæä¾›äº†æœ¬åœ°æ–‡ä»¶è·¯å¾„
        if local_file_path and os.path.exists(local_file_path):
            print(f"ğŸ“¤ Processing local PDF: {local_file_path}")
            task_id = create_task("", file_path=local_file_path)
        elif pdf_url:
            print(f"ğŸ“¥ Processing PDF from URL: {pdf_url}")
            task_id = create_task(pdf_url)
        else:
            return json.dumps({"error": "è¯·æä¾›PDF URLæˆ–æœ¬åœ°æ–‡ä»¶è·¯å¾„"})

        # æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å¹¶è·å–ç»“æœ
        zip_url = query_by_id(task_id)
        result = download_and_extract_zip(zip_url)

        return json.dumps({"result": result}, ensure_ascii=False)

    except Exception as e:
        return json.dumps({"error": str(e)})


@tool
def download_mineru_result(zip_url: str) -> str:
    """
    Download and extract MinerU parsing results.

    Args:
        zip_url: ZIP file URL from parse_pdf result

    Returns:
        JSON string with extracted content
    """
    try:
        result = download_and_extract_zip(zip_url)
        return json.dumps(result, ensure_ascii=False)
    except Exception as e:
        return json.dumps({"error": str(e)})


# ============================================================================
# Tool 2: ç®€å•çš„æ–‡æœ¬å¤„ç†å’Œå­˜å‚¨ (å†…å­˜å­˜å‚¨ï¼Œæ— æœ¬åœ°ä¾èµ–)
# ============================================================================

class SimpleTextStore:
    """ç®€å•çš„æ–‡æœ¬å­˜å‚¨ï¼Œä¸ä½¿ç”¨å‘é‡æ•°æ®åº“"""
    _instance = None
    _initialized = False

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if not self._initialized:
            self.texts = []
            self.index_path = Path("./data/text_index.json")
            self.index_path.parent.mkdir(parents=True, exist_ok=True)

            # å°è¯•åŠ è½½å·²æœ‰ç´¢å¼•
            if self.index_path.exists():
                try:
                    with open(self.index_path, 'r') as f:
                        self.texts = json.load(f)
                except Exception:
                    self.texts = []

            SimpleTextStore._initialized = True

    def add_texts(self, texts: List[str]):
        """æ·»åŠ æ–‡æœ¬"""
        self.texts.extend(texts)
        self._save()

    def search(self, query: str, top_k: int = 5) -> List[Dict]:
        """ç®€å•çš„æ–‡æœ¬æœç´¢ï¼ˆåŸºäºå…³é”®è¯åŒ¹é…ï¼‰"""
        if not self.texts:
            return []

        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        query_words = query.lower().split()
        results = []

        for text in self.texts:
            text_lower = text.lower()
            score = sum(1 for word in query_words if word in text_lower)
            if score > 0:
                results.append({
                    "text": text[:500] + "..." if len(text) > 500 else text,
                    "score": float(score)
                })

        # æŒ‰åˆ†æ•°æ’åº
        results.sort(key=lambda x: x["score"], reverse=True)
        return results[:top_k]

    def _save(self):
        """ä¿å­˜æ–‡æœ¬"""
        with open(self.index_path, 'w') as f:
            json.dump(self.texts, f)


# å…¨å±€æ–‡æœ¬å­˜å‚¨å®ä¾‹
text_store = SimpleTextStore()


@tool
def index_text(text: str, chunk_size: int = 500) -> str:
    """
    Index text by chunking and storing in memory.

    Args:
        text: Text to index
        chunk_size: Size of each chunk

    Returns:
        Status message
    """
    try:
        # ç®€å•çš„åˆ†å—
        sentences = text.replace('\n', ' ').split('ã€‚')
        sentences = [s.strip() + 'ã€‚' for s in sentences if s.strip()]

        chunks = []
        current_chunk = ""

        for sentence in sentences:
            if len(current_chunk) + len(sentence) < chunk_size:
                current_chunk += sentence
            else:
                if current_chunk:
                    chunks.append(current_chunk)
                current_chunk = sentence

        if current_chunk:
            chunks.append(current_chunk)

        # å­˜å‚¨åˆ°å†…å­˜
        text_store.add_texts(chunks)

        return f"Successfully indexed {len(chunks)} chunks"

    except Exception as e:
        return f"Error indexing text: {str(e)}"


@tool
def search_knowledge(query: str, top_k: int = 5) -> str:
    """
    Search for relevant information from indexed documents.

    Args:
        query: Search query
        top_k: Number of results to return

    Returns:
        JSON string of search results
    """
    try:
        results = text_store.search(query, top_k)
        return json.dumps(results, ensure_ascii=False)

    except Exception as e:
        return json.dumps({"error": str(e)})


# ============================================================================
# Tool 3: å›¾åƒç†è§£å·¥å…· (ä½¿ç”¨ Qwen-VL API)
# ============================================================================

@tool
def understand_image(image_path: str, question: str = "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾è¡¨") -> str:
    """
    Understand and describe an image using Qwen-VL model.

    Args:
        image_path: Path to the image file
        question: Question about the image

    Returns:
        Description of the image
    """
    try:
        import base64

        image_path = Path(image_path)
        if not image_path.exists():
            return f"Image not found: {image_path}"

        # è¯»å–å›¾åƒ
        with open(image_path, "rb") as f:
            image_data = base64.b64encode(f.read()).decode('utf-8')

        # è°ƒç”¨Qwen-VL API (é­”æ­)
        client = OpenAI(
            api_key=os.getenv("MODELSCOPE_API_KEY"),
            base_url=os.getenv("MODELSCOPE_BASE_URL")
        )

        response = client.chat.completions.create(
            model="qwen-vl-max",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_data}"
                            }
                        },
                        {
                            "type": "text",
                            "text": question
                        }
                    ]
                }
            ]
        )

        return response.choices[0].message.content

    except Exception as e:
        return f"Error understanding image: {str(e)}"


# ============================================================================
# Tool 4: ç»¼åˆå·¥å…· - å¤„ç†æ•´ä¸ªPDFå¹¶ç´¢å¼•
# ============================================================================

@tool
def process_and_index_pdf(pdf_url: str) -> str:
    """
    Process a PDF file with MinerU and index the content.

    Args:
        pdf_url: URL to PDF file

    Returns:
        Processing summary
    """
    try:
        # 1. è§£æPDF
        print(f"ğŸ“„ Starting PDF processing...")
        parse_result = parse_pdf(pdf_url)
        result_dict = json.loads(parse_result)

        if "error" in result_dict:
            return parse_result

        zip_url = result_dict.get("zip_url")
        if not zip_url:
            return json.dumps({"error": "No zip_url in result"})

        # 2. ä¸‹è½½ç»“æœ
        print(f"ğŸ“¥ Downloading results...")
        download_result = download_mineru_result(zip_url)
        download_dict = json.loads(download_result)

        if "error" in download_dict:
            return download_result

        # 3. æå–æ–‡æœ¬
        markdown = download_dict.get("markdown", "")
        if not markdown:
            return json.dumps({"error": "No markdown content found"})

        print(f"ğŸ“ Indexing text...")
        index_status = index_text(markdown)

        # 4. è¿”å›æ‘˜è¦
        summary = {
            "markdown_length": len(markdown),
            "images_count": len(download_dict.get("images", [])),
            "tables_count": len(download_dict.get("tables", [])),
            "index_status": index_status,
            "images": download_dict.get("images", []),
            "markdown_preview": markdown[:500] + "..." if len(markdown) > 500 else markdown
        }

        return json.dumps(summary, ensure_ascii=False, indent=2)

    except Exception as e:
        return json.dumps({"error": str(e)})


# å¯¼å‡ºæ‰€æœ‰å·¥å…·
__all__ = [
    'parse_pdf',
    'download_mineru_result',
    'index_text',
    'search_knowledge',
    'understand_image',
    'process_and_index_pdf'
]
