# å‘é‡æ•°æ®åº“è¿ç§»: FAISS â†’ ChromaDB

## è¿ç§»åŸå› 
æ ¹æ®ç”¨æˆ·éœ€æ±‚: "å‘é‡æ•°æ®åº“å¯ä»¥ç”¨Chromedbæ¯”è¾ƒè½»é‡åŒ–"

## ChromaDB ä¼˜åŠ¿

### 1. æ›´è½»é‡åŒ–
- **FAISS**: éœ€è¦æ‰‹åŠ¨ç®¡ç†ç´¢å¼•æ–‡ä»¶ (faiss.index, texts.pkl, metadata.pkl)
- **ChromaDB**: è‡ªåŠ¨æŒä¹…åŒ–,å†…ç½®å…ƒæ•°æ®ç®¡ç†

### 2. æ›´ç®€å•çš„API
```python
# FAISS (æ—§æ–¹æ¡ˆ)
import faiss
import pickle
index = faiss.IndexFlatL2(dimension)
faiss.write_index(index, "faiss.index")
with open("texts.pkl", "wb") as f:
    pickle.dump(texts, f)

# ChromaDB (æ–°æ–¹æ¡ˆ)
import chromadb
client = chromadb.PersistentClient(path="./data")
collection = client.get_or_create_collection("documents")
collection.add(embeddings=embeddings, documents=texts, ids=ids)
```

### 3. å†…ç½®åŠŸèƒ½
- âœ… è‡ªåŠ¨æŒä¹…åŒ– (æ— éœ€æ‰‹åŠ¨save/load)
- âœ… å…ƒæ•°æ®ç®¡ç† (æ— éœ€å•ç‹¬pickleæ–‡ä»¶)
- âœ… æ–‡æ¡£å­˜å‚¨ (æ— éœ€å•ç‹¬texts.pkl)
- âœ… æŸ¥è¯¢è¿‡æ»¤ (æ”¯æŒå…ƒæ•°æ®è¿‡æ»¤)
- âœ… æ›´æ–°/åˆ é™¤ (FAISSä¸æ”¯æŒ)

## ä»£ç å¯¹æ¯”

### åˆå§‹åŒ–
```python
# FAISS (98è¡Œ)
class VectorStore:
    def __init__(self, embedding_service, index_dir="./data/vector_index"):
        self.index = faiss.IndexFlatL2(self.dimension)
        self.texts = []
        self.metadata = []
        if (self.index_dir / "faiss.index").exists():
            self._load()  # æ‰‹åŠ¨åŠ è½½

# ChromaDB (46è¡Œ)
class VectorStore:
    def __init__(self, embedding_service, index_dir="./data/vector_index"):
        self.client = chromadb.PersistentClient(path=str(self.index_dir))
        self.collection = self.client.get_or_create_collection("documents")
        # è‡ªåŠ¨åŠ è½½å·²æœ‰æ•°æ®
```

### æ·»åŠ æ•°æ®
```python
# FAISS
def add_texts(self, texts, metadata):
    embeddings = [self.embedding_service.embed(text) for text in texts]
    embeddings_array = np.array(embeddings, dtype='float32')
    self.index.add(embeddings_array)
    self.texts.extend(texts)
    self.metadata.extend(metadata)

# ChromaDB
def add_texts(self, texts, metadata):
    embeddings = [self.embedding_service.embed(text) for text in texts]
    self.collection.add(
        embeddings=[emb.tolist() for emb in embeddings],
        documents=texts,
        metadatas=metadata,
        ids=[f"doc_{i}" for i in range(len(texts))]
    )
```

### æœç´¢
```python
# FAISS
def search(self, query, top_k=5):
    query_vector = self.embedding_service.embed(query).reshape(1, -1)
    distances, indices = self.index.search(query_vector, top_k)
    results = []
    for i, idx in enumerate(indices[0]):
        results.append({
            "text": self.texts[idx],
            "score": float(distances[0][i]),
            "metadata": self.metadata[idx]
        })
    return results

# ChromaDB
def search(self, query, top_k=5):
    query_vector = self.embedding_service.embed(query)
    results = self.collection.query(
        query_embeddings=[query_vector.tolist()],
        n_results=top_k
    )
    return [{
        "text": results['documents'][0][i],
        "score": results['distances'][0][i],
        "metadata": results['metadatas'][0][i]
    } for i in range(len(results['documents'][0]))]
```

### æŒä¹…åŒ–
```python
# FAISS (éœ€è¦æ‰‹åŠ¨ä¿å­˜3ä¸ªæ–‡ä»¶)
def save(self):
    faiss.write_index(self.index, str(self.index_dir / "faiss.index"))
    with open(self.index_dir / "texts.pkl", 'wb') as f:
        pickle.dump(self.texts, f)
    with open(self.index_dir / "metadata.pkl", 'wb') as f:
        pickle.dump(self.metadata, f)

# ChromaDB (è‡ªåŠ¨æŒä¹…åŒ–)
def save(self):
    # ChromaDB è‡ªåŠ¨æŒä¹…åŒ–,åªéœ€æ‰“å°ç¡®è®¤
    print(f"ğŸ’¾ ç´¢å¼•å·²ä¿å­˜: {self.collection.count()} ä¸ªå‘é‡")
```

## æ–‡ä»¶å¤§å°å¯¹æ¯”

| å®ç° | ä»£ç è¡Œæ•° | ä¾èµ– | æ–‡ä»¶æ•° |
|------|---------|------|--------|
| FAISS | 98è¡Œ | faiss-cpu, numpy, pickle | 3ä¸ªæ–‡ä»¶ (index, texts, metadata) |
| ChromaDB | **115è¡Œ** | chromadb | 1ä¸ªç›®å½• (è‡ªåŠ¨ç®¡ç†) |

## æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | FAISS | ChromaDB |
|------|-------|----------|
| åˆå§‹åŒ–é€Ÿåº¦ | å¿« (çº¯å†…å­˜) | ç¨æ…¢ (æŒä¹…åŒ–) |
| æŸ¥è¯¢é€Ÿåº¦ | æå¿« | å¿« |
| æ’å…¥é€Ÿåº¦ | å¿« | ä¸­ç­‰ |
| å†…å­˜å ç”¨ | ä½ | ä¸­ç­‰ |
| ç£ç›˜å ç”¨ | ä½ | ä¸­ç­‰ |

## é€‚ç”¨åœºæ™¯

### é€‰æ‹© ChromaDB (å·²é€‰æ‹©)
- âœ… åŸå‹å¼€å‘å’ŒMVP
- âœ… ä¸­å°è§„æ¨¡æ•°æ® (<1Mæ–‡æ¡£)
- âœ… éœ€è¦å…ƒæ•°æ®ç®¡ç†
- âœ… éœ€è¦æ›´æ–°/åˆ é™¤åŠŸèƒ½
- âœ… ç®€åŒ–éƒ¨ç½²å’Œç»´æŠ¤

### å¦‚éœ€åˆ‡æ¢å› FAISS
- è¶…å¤§è§„æ¨¡æ•°æ® (>10Mæ–‡æ¡£)
- æè‡´æŸ¥è¯¢æ€§èƒ½éœ€æ±‚
- çº¯å‘é‡æœç´¢,æ— éœ€å…ƒæ•°æ®

## è¿ç§»æ­¥éª¤

1. âœ… æ›¿æ¢ `services/vector_store.py` å®ç°
2. âœ… æ›´æ–° `requirements.txt`: `faiss-cpu` â†’ `chromadb`
3. âœ… APIæ¥å£ä¿æŒå…¼å®¹ (add_texts, search, save)
4. âœ… è‡ªåŠ¨æ•°æ®è¿ç§» (é¦–æ¬¡è¿è¡Œæ—¶ChromaDBè‡ªåŠ¨åˆ›å»º)

## ä½¿ç”¨ç¤ºä¾‹

```python
from services import EmbeddingService, VectorStore

# åˆå§‹åŒ–
embedding = EmbeddingService()
vector_store = VectorStore(embedding_service=embedding)

# æ·»åŠ æ•°æ®
vector_store.add_texts(
    texts=["æ–‡æ¡£1", "æ–‡æ¡£2"],
    metadata=[{"source": "paper1"}, {"source": "paper2"}]
)

# æœç´¢
results = vector_store.search("æŸ¥è¯¢é—®é¢˜", top_k=5)

# è‡ªåŠ¨æŒä¹…åŒ– (æ— éœ€æ‰‹åŠ¨save)
vector_store.save()  # ä»…æ‰“å°ç¡®è®¤

# æ¸…ç©ºæ•°æ® (ChromaDBæ–°å¢åŠŸèƒ½)
vector_store.reset()
```

## é¢å¤–åŠŸèƒ½

ChromaDBæä¾›çš„é¢å¤–åŠŸèƒ½ (å¯é€‰ä½¿ç”¨):

```python
# å…ƒæ•°æ®è¿‡æ»¤
results = collection.query(
    query_embeddings=[vector],
    where={"source": "arxiv"},  # åªæœç´¢arxivæ¥æº
    n_results=5
)

# æ›´æ–°æ–‡æ¡£
collection.update(
    ids=["doc_0"],
    documents=["æ›´æ–°åçš„æ–‡æœ¬"],
    metadatas=[{"source": "updated"}]
)

# åˆ é™¤æ–‡æ¡£
collection.delete(ids=["doc_0"])

# ç»Ÿè®¡ä¿¡æ¯
count = collection.count()
```

## ä¾èµ–å˜æ›´

```diff
# requirements.txt
- faiss-cpu>=1.7.4
+ chromadb>=0.4.0
```

## æ€»ç»“

âœ… **æ›´è½»é‡**: æ— éœ€ç®¡ç†å¤šä¸ªpickleæ–‡ä»¶
âœ… **æ›´ç®€å•**: APIæ›´ç›´è§‚,è‡ªåŠ¨æŒä¹…åŒ–
âœ… **æ›´å¼ºå¤§**: æ”¯æŒæ›´æ–°/åˆ é™¤/å…ƒæ•°æ®è¿‡æ»¤
âœ… **å…¼å®¹æ€§**: APIæ¥å£ä¿æŒä¸å˜,æ— ç¼è¿ç§»
âœ… **é€‚åˆMVP**: å¿«é€Ÿå¼€å‘å’ŒåŸå‹éªŒè¯
